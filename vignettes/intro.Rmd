---
title: "autoparallel-introduction"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{autoparallel-introduction}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

TODO: include use case

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    eval = FALSE
)
```

Goal is to release on CRAN in early June 2018. 
Include the following features:

- lapply -> mclapply
- for loop -> parallel
- task parallel expressions

These should work with Unix fork (priority) and SNOW parallel setups, which
means properly detecting and synchronizing state.

For later:

- Nested subexpressions. If the top level expression graph works then
  we can use a preprocessing step to create temporary variables and then
  use the same task parallel stuff.

I want to export as few functions as possible, probably just 1 or 2.

# Introduction

This package is meant to simplify parallel programming in R by automating
common tasks.

My goal in creating this package was to produce something that I find
personally useful.

As data sizes and processor counts increase, parallelism becomes more
important.

Parallel programming can be challenging, because it requires further levels
of expertise. The core of R is a functional language, and the functional
paradigm is well suited to parallel programming. 

R functions typically don't have side effects. They don't modify their
arguments; instead they produce new objects. This is what makes R
functional and what allows us to do parallel computing.


## Prior Art

SNOW, parallel packages now included with R as recommended packages.

Bohringer's dynamic parallelization.

Bengsston's futures.


## User functions

Most users should interact with this software through the functions
described in this subsection. Our goal is to make this easy to use by
providing only a few functions that are extensible. 

Suppose you have a script `code.R` in R's current working directory.
If you just want a quick transformation of your code into a parallel form
then can do the following:

```{R}

library(autoparallel)

autoparallel("code.R")
```

This generates a parallel version of `code.R`.

Internally it takes the following steps:

1. Parses the file `code.R`
2. Converts R's AST into an intermediate representation (IR) that's more
   suitable for analysis
3. Statically analyzes the IR to detect the potential for parallelism
4. Detects the capabilities of the system
5. Combines the the static analysis with the system capabilities to produce
   an execution plan
6. Saves the generated plan into a file


`parallelize()` takes user code and figures out an intelligent way to make
it parallel by inferring the dependency structure of the expressions and
the other patterns described in this document. It produces executable R
code that is now parallel.

```{R}
pcode = parallelize("code.R"
    , clean_first = FALSE
    , run_now = FALSE
    , cluster_type = "FORK"
    , nnodes = 4
)

# visual representation of the graph structure
plot(pcode)

# Save the parallel version of the script
save_code(pcode, "pcode.R")

# Run the whole thing interactively
run_code(pcode)
```

TODO: I'm not satisfied with the extensibility of these high level
functions. To tell if it's worth it to parallelize we would really like to
know the `object.size()` of as many variables as we can, as well as the
times to execute each statement. So we need a way for users to provide that
information if they have it. I can think of a few hacky ways, see the
bottom of this document below Scratch:

## Future directions

Things that we haven't yet implemented, but we plan to.

- More code transformations
